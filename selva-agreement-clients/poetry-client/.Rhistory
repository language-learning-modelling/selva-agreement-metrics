quit()
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages({
library(tidyverse)
library(stringdist)
library(stringi)
library(cleanNLP)
library(jsonlite)
})
options(dplyr.summarise.inform = FALSE)
options(width = 120)
theme_set(theme_minimal())
cnlp_init_udpipe()
###############################################################
# JSON=>CSV (Taylor Arnold fecit)
jtext <- read_lines("celva.sp_full_dataset.json")
#jtext <- read_lines("../data/selva_full_dataset(3).json")
jtext <- stri_replace_all(jtext, "null", fixed = "NaN")
jd <- jsonlite::fromJSON(jtext)
df <- vector('list', length(jd))
for (j in seq_along(jd)){
z <- jd[[j]]
mods <- z$predictions$models
temp <- bind_rows(mods$predictions)
temp$model <- rep(mods$model_name, each = 3)
temp$rank <- rep(1:3, 3)
for (nom in names(jd[[j]]$metadata))
{
temp[[nom]] <- jd[[j]]$metadata[[nom]]
}
temp$name <- names(jd)[j]
temp$maskedToken_token_str <- z$predictions$maskedToken$token_str
temp$maskedToken_ud_pos <- z$predictions$maskedToken$ud_pos
temp$maskedSentenceStr <- z$predictions$maskedSentenceStr
temp$maskedTokenIdx <- z$predictions$maskedTokenIdx
temp$maskedTokenStr <- z$predictions$maskedTokenStr
df[[j]] <- as_tibble(temp)
}
df <- bind_rows(df)
df <- select(df, name, everything())
# adding a success variable when the token has been predicted by the LLM
df$success <- as.numeric(df$token_str == df$maskedTokenStr)
success <- df %>% filter(success == 1)
prop.modl <- prop.table(table(success$model))
# Define table caption (optional)
table_caption3 <- "Proportions of exact tokens predicted by the different models"
# Create xtable object with basic formatting
xtable(prop.modl, caption = table_caption3)
install.packages("xtable")
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages({
library(tidyverse)
library(stringdist)
library(stringi)
library(cleanNLP)
library(jsonlite)
})
options(dplyr.summarise.inform = FALSE)
options(width = 120)
theme_set(theme_minimal())
cnlp_init_udpipe()
###############################################################
# JSON=>CSV (Taylor Arnold fecit)
jtext <- read_lines("celva.sp_full_dataset.json")
#jtext <- read_lines("../data/selva_full_dataset(3).json")
jtext <- stri_replace_all(jtext, "null", fixed = "NaN")
jd <- jsonlite::fromJSON(jtext)
df <- vector('list', length(jd))
for (j in seq_along(jd)){
z <- jd[[j]]
mods <- z$predictions$models
temp <- bind_rows(mods$predictions)
temp$model <- rep(mods$model_name, each = 3)
temp$rank <- rep(1:3, 3)
for (nom in names(jd[[j]]$metadata))
{
temp[[nom]] <- jd[[j]]$metadata[[nom]]
}
temp$name <- names(jd)[j]
temp$maskedToken_token_str <- z$predictions$maskedToken$token_str
temp$maskedToken_ud_pos <- z$predictions$maskedToken$ud_pos
temp$maskedSentenceStr <- z$predictions$maskedSentenceStr
temp$maskedTokenIdx <- z$predictions$maskedTokenIdx
temp$maskedTokenStr <- z$predictions$maskedTokenStr
df[[j]] <- as_tibble(temp)
}
df <- bind_rows(df)
df <- select(df, name, everything())
# adding a success variable when the token has been predicted by the LLM
df$success <- as.numeric(df$token_str == df$maskedTokenStr)
success <- df %>% filter(success == 1)
prop.modl <- prop.table(table(success$model))
# Define table caption (optional)
table_caption3 <- "Proportions of exact tokens predicted by the different models"
# Create xtable object with basic formatting
xtable(prop.modl, caption = table_caption3)
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages({
library(tidyverse)
library(stringdist)
library(stringi)
library(cleanNLP)
library(jsonlite)
library(xtable)
})
options(dplyr.summarise.inform = FALSE)
options(width = 120)
theme_set(theme_minimal())
cnlp_init_udpipe()
###############################################################
# JSON=>CSV (Taylor Arnold fecit)
jtext <- read_lines("celva.sp_full_dataset.json")
#jtext <- read_lines("../data/selva_full_dataset(3).json")
jtext <- stri_replace_all(jtext, "null", fixed = "NaN")
jd <- jsonlite::fromJSON(jtext)
df <- vector('list', length(jd))
for (j in seq_along(jd)){
z <- jd[[j]]
mods <- z$predictions$models
temp <- bind_rows(mods$predictions)
temp$model <- rep(mods$model_name, each = 3)
temp$rank <- rep(1:3, 3)
for (nom in names(jd[[j]]$metadata))
{
temp[[nom]] <- jd[[j]]$metadata[[nom]]
}
temp$name <- names(jd)[j]
temp$maskedToken_token_str <- z$predictions$maskedToken$token_str
temp$maskedToken_ud_pos <- z$predictions$maskedToken$ud_pos
temp$maskedSentenceStr <- z$predictions$maskedSentenceStr
temp$maskedTokenIdx <- z$predictions$maskedTokenIdx
temp$maskedTokenStr <- z$predictions$maskedTokenStr
df[[j]] <- as_tibble(temp)
}
df <- bind_rows(df)
df <- select(df, name, everything())
# adding a success variable when the token has been predicted by the LLM
df$success <- as.numeric(df$token_str == df$maskedTokenStr)
success <- df %>% filter(success == 1)
prop.modl <- prop.table(table(success$model))
# Define table caption (optional)
table_caption3 <- "Proportions of exact tokens predicted by the different models"
# Create xtable object with basic formatting
xtable(prop.modl, caption = table_caption3)
# Print the LaTeX code (use cat() to write to a file)
cat(print(xtable(prop.modl, caption = table_caption3), include.rownames = FALSE, include.colnames = TRUE), file = "my_propmodl.tex")
failed = df %>% filter(success == 0 & rank == 1 & model == "../models/bert-base-uncased-fullefcamdat/") %>%
select(model, rank, success, score)
failed %>% ggplot(aes(x=score)) + geom_density()
# Select number of clusters
k <- 3
set.seed(12345)
# Build model with k clusters
km.out <- kmeans(failed$score, centers = 2)
library(factoextra)
install.packages("factoextra")
install.packages("Cairo")
install.packages("hunspell")
install.packages("entropy")
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages({
library(tidyverse)
library(stringdist)
library(stringi)
library(cleanNLP)
library(jsonlite)
library(xtable)
})
options(dplyr.summarise.inform = FALSE)
options(width = 120)
theme_set(theme_minimal())
cnlp_init_udpipe()
###############################################################
# JSON=>CSV (Taylor Arnold fecit)
jtext <- read_lines("celva.sp_full_dataset.json")
#jtext <- read_lines("../data/selva_full_dataset(3).json")
jtext <- stri_replace_all(jtext, "null", fixed = "NaN")
jd <- jsonlite::fromJSON(jtext)
df <- vector('list', length(jd))
for (j in seq_along(jd)){
z <- jd[[j]]
mods <- z$predictions$models
temp <- bind_rows(mods$predictions)
temp$model <- rep(mods$model_name, each = 3)
temp$rank <- rep(1:3, 3)
for (nom in names(jd[[j]]$metadata))
{
temp[[nom]] <- jd[[j]]$metadata[[nom]]
}
temp$name <- names(jd)[j]
temp$maskedToken_token_str <- z$predictions$maskedToken$token_str
temp$maskedToken_ud_pos <- z$predictions$maskedToken$ud_pos
temp$maskedSentenceStr <- z$predictions$maskedSentenceStr
temp$maskedTokenIdx <- z$predictions$maskedTokenIdx
temp$maskedTokenStr <- z$predictions$maskedTokenStr
df[[j]] <- as_tibble(temp)
}
df <- bind_rows(df)
df <- select(df, name, everything())
# adding a success variable when the token has been predicted by the LLM
df$success <- as.numeric(df$token_str == df$maskedTokenStr)
success <- df %>% filter(success == 1)
prop.modl <- prop.table(table(success$model))
# Define table caption (optional)
table_caption3 <- "Proportions of exact tokens predicted by the different models"
# Create xtable object with basic formatting
xtable(prop.modl, caption = table_caption3)
# Print the LaTeX code (use cat() to write to a file)
cat(print(xtable(prop.modl, caption = table_caption3), include.rownames = FALSE, include.colnames = TRUE), file = "my_propmodl.tex")
failed = df %>% filter(success == 0 & rank == 1 & model == "../models/bert-base-uncased-fullefcamdat/") %>%
select(model, rank, success, score)
failed %>% ggplot(aes(x=score)) + geom_density()
# Select number of clusters
k <- 3
set.seed(12345)
# Build model with k clusters
km.out <- kmeans(failed$score, centers = 2)
library(factoextra)
install.packages("factoextra")
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages({
library(tidyverse)
library(stringdist)
library(stringi)
library(cleanNLP)
library(jsonlite)
library(xtable)
})
options(dplyr.summarise.inform = FALSE)
options(width = 120)
theme_set(theme_minimal())
cnlp_init_udpipe()
###############################################################
# JSON=>CSV (Taylor Arnold fecit)
jtext <- read_lines("celva.sp_full_dataset.json")
#jtext <- read_lines("../data/selva_full_dataset(3).json")
jtext <- stri_replace_all(jtext, "null", fixed = "NaN")
jd <- jsonlite::fromJSON(jtext)
df <- vector('list', length(jd))
for (j in seq_along(jd)){
z <- jd[[j]]
mods <- z$predictions$models
temp <- bind_rows(mods$predictions)
temp$model <- rep(mods$model_name, each = 3)
temp$rank <- rep(1:3, 3)
for (nom in names(jd[[j]]$metadata))
{
temp[[nom]] <- jd[[j]]$metadata[[nom]]
}
temp$name <- names(jd)[j]
temp$maskedToken_token_str <- z$predictions$maskedToken$token_str
temp$maskedToken_ud_pos <- z$predictions$maskedToken$ud_pos
temp$maskedSentenceStr <- z$predictions$maskedSentenceStr
temp$maskedTokenIdx <- z$predictions$maskedTokenIdx
temp$maskedTokenStr <- z$predictions$maskedTokenStr
df[[j]] <- as_tibble(temp)
}
df <- bind_rows(df)
df <- select(df, name, everything())
# adding a success variable when the token has been predicted by the LLM
df$success <- as.numeric(df$token_str == df$maskedTokenStr)
success <- df %>% filter(success == 1)
prop.modl <- prop.table(table(success$model))
# Define table caption (optional)
table_caption3 <- "Proportions of exact tokens predicted by the different models"
# Create xtable object with basic formatting
xtable(prop.modl, caption = table_caption3)
# Print the LaTeX code (use cat() to write to a file)
cat(print(xtable(prop.modl, caption = table_caption3), include.rownames = FALSE, include.colnames = TRUE), file = "my_propmodl.tex")
failed = df %>% filter(success == 0 & rank == 1 & model == "../models/bert-base-uncased-fullefcamdat/") %>%
select(model, rank, success, score)
failed %>% ggplot(aes(x=score)) + geom_density()
# Select number of clusters
k <- 3
set.seed(12345)
# Build model with k clusters
km.out <- kmeans(failed$score, centers = 2)
library(factoextra)
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages({
library(tidyverse)
library(stringdist)
library(stringi)
library(cleanNLP)
library(jsonlite)
library(xtable)
})
options(dplyr.summarise.inform = FALSE)
options(width = 120)
theme_set(theme_minimal())
cnlp_init_udpipe()
###############################################################
# JSON=>CSV (Taylor Arnold fecit)
jtext <- read_lines("celva.sp_full_dataset.json")
#jtext <- read_lines("../data/selva_full_dataset(3).json")
jtext <- stri_replace_all(jtext, "null", fixed = "NaN")
jd <- jsonlite::fromJSON(jtext)
df <- vector('list', length(jd))
for (j in seq_along(jd)){
z <- jd[[j]]
mods <- z$predictions$models
temp <- bind_rows(mods$predictions)
temp$model <- rep(mods$model_name, each = 3)
temp$rank <- rep(1:3, 3)
for (nom in names(jd[[j]]$metadata))
{
temp[[nom]] <- jd[[j]]$metadata[[nom]]
}
temp$name <- names(jd)[j]
temp$maskedToken_token_str <- z$predictions$maskedToken$token_str
temp$maskedToken_ud_pos <- z$predictions$maskedToken$ud_pos
temp$maskedSentenceStr <- z$predictions$maskedSentenceStr
temp$maskedTokenIdx <- z$predictions$maskedTokenIdx
temp$maskedTokenStr <- z$predictions$maskedTokenStr
df[[j]] <- as_tibble(temp)
}
df <- bind_rows(df)
df <- select(df, name, everything())
# adding a success variable when the token has been predicted by the LLM
df$success <- as.numeric(df$token_str == df$maskedTokenStr)
success <- df %>% filter(success == 1)
prop.modl <- prop.table(table(success$model))
# Define table caption (optional)
table_caption3 <- "Proportions of exact tokens predicted by the different models"
# Create xtable object with basic formatting
xtable(prop.modl, caption = table_caption3)
# Print the LaTeX code (use cat() to write to a file)
cat(print(xtable(prop.modl, caption = table_caption3), include.rownames = FALSE, include.colnames = TRUE), file = "my_propmodl.tex")
failed = df %>% filter(success == 0 & rank == 1 & model == "../models/bert-base-uncased-fullefcamdat/") %>%
select(model, rank, success, score)
failed %>% ggplot(aes(x=score)) + geom_density()
# Select number of clusters
k <- 3
set.seed(12345)
# Build model with k clusters
km.out <- kmeans(failed$score, centers = 2)
install.packages("factoextra")
library(factoextra)
install.packages("ggpubr")
install.packages("~/Downloads/factoextra_1.0.7.tar.gz", repos = NULL, type = "source")
install.packages("FactoMineR")
install.packages(c("car", "emmeans", "flashClust", "leaps", "FactoMineR"))
install.packages("car")
install.packages(c("pbkrtest", "quantreg", "lme4"))
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages({
library(tidyverse)
library(stringdist)
library(stringi)
library(cleanNLP)
library(jsonlite)
library(xtable)
})
options(dplyr.summarise.inform = FALSE)
options(width = 120)
theme_set(theme_minimal())
cnlp_init_udpipe()
###############################################################
# JSON=>CSV (Taylor Arnold fecit)
jtext <- read_lines("celva.sp_full_dataset.json")
#jtext <- read_lines("../data/selva_full_dataset(3).json")
jtext <- stri_replace_all(jtext, "null", fixed = "NaN")
jd <- jsonlite::fromJSON(jtext)
df <- vector('list', length(jd))
for (j in seq_along(jd)){
z <- jd[[j]]
mods <- z$predictions$models
temp <- bind_rows(mods$predictions)
temp$model <- rep(mods$model_name, each = 3)
temp$rank <- rep(1:3, 3)
for (nom in names(jd[[j]]$metadata))
{
temp[[nom]] <- jd[[j]]$metadata[[nom]]
}
temp$name <- names(jd)[j]
temp$maskedToken_token_str <- z$predictions$maskedToken$token_str
temp$maskedToken_ud_pos <- z$predictions$maskedToken$ud_pos
temp$maskedSentenceStr <- z$predictions$maskedSentenceStr
temp$maskedTokenIdx <- z$predictions$maskedTokenIdx
temp$maskedTokenStr <- z$predictions$maskedTokenStr
df[[j]] <- as_tibble(temp)
}
df <- bind_rows(df)
df <- select(df, name, everything())
# adding a success variable when the token has been predicted by the LLM
df$success <- as.numeric(df$token_str == df$maskedTokenStr)
success <- df %>% filter(success == 1)
prop.modl <- prop.table(table(success$model))
# Define table caption (optional)
table_caption3 <- "Proportions of exact tokens predicted by the different models"
# Create xtable object with basic formatting
xtable(prop.modl, caption = table_caption3)
# Print the LaTeX code (use cat() to write to a file)
cat(print(xtable(prop.modl, caption = table_caption3), include.rownames = FALSE, include.colnames = TRUE), file = "my_propmodl.tex")
failed = df %>% filter(success == 0 & rank == 1 & model == "../models/bert-base-uncased-fullefcamdat/") %>%
select(model, rank, success, score)
failed %>% ggplot(aes(x=score)) + geom_density()
# Select number of clusters
k <- 3
set.seed(12345)
# Build model with k clusters
km.out <- kmeans(failed$score, centers = 2)
install.packages("factoextra",dependencies = TRUE)
library(factoextra)
installed.packages('ggpub', dependencies=TRUE)
\
installed.packages('ggpub', dependencies=TRUE)
install.packages("ggpub",dependencies = TRUE)
install.packages("nloptr",dependencies = TRUE)
install.packages("ggpub",dependencies = TRUE)
